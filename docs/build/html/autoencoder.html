<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>autoencoder module &mdash; Project 4Bim 2022 Group 2 0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="genetic_algorithm module" href="genetic_algorithm.html" />
    <link rel="prev" title="project4bim2022_g2" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> Project 4Bim 2022 Group 2
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">project4bim2022_g2</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">autoencoder module</a></li>
<li class="toctree-l2"><a class="reference internal" href="genetic_algorithm.html">genetic_algorithm module</a></li>
<li class="toctree-l2"><a class="reference internal" href="robot_portrait.html">robot_portrait module</a></li>
<li class="toctree-l2"><a class="reference internal" href="utils.html">utils module</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Project 4Bim 2022 Group 2</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">project4bim2022_g2</a> &raquo;</li>
      <li>autoencoder module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/autoencoder.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-autoencoder">
<span id="autoencoder-module"></span><h1>autoencoder module<a class="headerlink" href="#module-autoencoder" title="Permalink to this headline"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.generate_images">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">generate_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.generate_images" title="Permalink to this definition"></a></dt>
<dd><p>The function takes the prior distribution, decoder and number of samples as inputs, which
should be used to generate the images.
The function should then return the batch of generated images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prior</strong> (<em>MixtureSameFamily</em>) – prior distribution</p></li>
<li><p><strong>decoder</strong> (<em>Sequential</em>) – trained decoder of the vae</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – targeted number of samples</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>images generated</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.generate_latent_vectors">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">generate_latent_vectors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.generate_latent_vectors" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.get_decoder">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">get_decoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.get_decoder" title="Permalink to this definition"></a></dt>
<dd><p>generates the decoder of the vae, with a given latent dimension</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>latent_dim</strong> (<em>int</em>) – latent dimension the image is encoded into</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>decoder of the vae model</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.engine.sequential.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.get_encoder">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">get_encoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kl_regularizer</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.get_encoder" title="Permalink to this definition"></a></dt>
<dd><p>generates an encoder with a given latent dimension and a kl regularizer</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_dim</strong> (<em>int</em>) – dimension of the latent space we want to encode the image to</p></li>
<li><p><strong>kl_regularizer</strong> (<em>tensorflow_probability.python.layers.distribution_layer.KLDivergenceRegularizer</em>) – kl regularizer</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>encoder with all the layers we want</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>keras.engine.sequential.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.get_kl_regularizer">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">get_kl_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior_distribution</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.get_kl_regularizer" title="Permalink to this definition"></a></dt>
<dd><p>The kl regularizer is a part of the loss function. It takes the prior distribution as an
input will be used as the activity_regularizer of the tfpl.MultivariateNormalTriL layer of the encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>prior_distribution</strong> (<em>tfp.distributions.MixtureSameFamily</em>) – </p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tensorflow_probability.python.layers.distribution_layer.KLDivergenceRegularizer</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.get_prior">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">get_prior</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_modes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">latent_dim</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.get_prior" title="Permalink to this definition"></a></dt>
<dd><p>Creates a mixture of gaussian distribution.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_modes</strong> (<em>int</em>) – </p></li>
<li><p><strong>latent_dim</strong> (<em>int</em>) – latent dimension we want to encode the image in</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Mixture of gaussian distribution, with variable means and
standart deviations</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tfp.distributions.MixtureSameFamily</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.load_labels_and_image_arrays">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">load_labels_and_image_arrays</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">split</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.load_labels_and_image_arrays" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.plot_generate_images">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">plot_generate_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prior</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.plot_generate_images" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.plot_reconstructions_test_ds">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">plot_reconstructions_test_ds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.plot_reconstructions_test_ds" title="Permalink to this definition"></a></dt>
<dd><p>plots the reconstruction of the images versus the initial images</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Sequential</em>) – encoder of the vae</p></li>
<li><p><strong>decoder</strong> (<em>Sequential</em>) – decoder of the vae</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.plot_recontructed_images">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">plot_recontructed_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.plot_recontructed_images" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.reconstruct">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">reconstruct</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">encoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_of_images</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.reconstruct" title="Permalink to this definition"></a></dt>
<dd><p>The function takes the encoder, decoder and batch_of_images as inputs, which
should be used to compute the reconstructions.
The function should then return the reconstructions Tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder</strong> (<em>Sequential</em>) – encoder of the model</p></li>
<li><p><strong>decoder</strong> (<em>Sequential</em>) – decoder of the model</p></li>
<li><p><strong>batch_of_images</strong> (<em>ndarray</em>) – list of images we want to reconstruct</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>reconstruction tensor</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.reconstruct_image_from_latent_vectors">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">reconstruct_image_from_latent_vectors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">decoder</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Z</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.reconstruct_image_from_latent_vectors" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.reconstruction_loss">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">reconstruction_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_of_images</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoding_dist</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.reconstruction_loss" title="Permalink to this definition"></a></dt>
<dd><p>The function takes batch_of_images (Tensor containing a batch of input images to
the encoder) and decoding_dist (output distribution of decoder after passing the
image batch through the encoder and decoder) as arguments.
The function should return the scalar average expected reconstruction loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>scalar average expected reconstruction loss</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tf.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="autoencoder.train">
<span class="sig-prename descclassname"><span class="pre">autoencoder.</span></span><span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">vae</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_ds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_ds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#autoencoder.train" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="project4bim2022_g2" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="genetic_algorithm.html" class="btn btn-neutral float-right" title="genetic_algorithm module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Group 2.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>